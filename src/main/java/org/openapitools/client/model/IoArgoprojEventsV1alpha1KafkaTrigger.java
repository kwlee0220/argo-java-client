/*
 * Argo Workflows API
 * Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. For more information, please see https://argo-workflows.readthedocs.io/en/latest/
 *
 * The version of the OpenAPI document: VERSION
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import org.openapitools.client.model.IoArgoprojEventsV1alpha1SASLConfig;
import org.openapitools.client.model.IoArgoprojEventsV1alpha1SchemaRegistryConfig;
import org.openapitools.client.model.IoArgoprojEventsV1alpha1TLSConfig;
import org.openapitools.client.model.IoArgoprojEventsV1alpha1TriggerParameter;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * KafkaTrigger refers to the specification of the Kafka trigger.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2025-02-24T03:51:41.763920791Z[Etc/UTC]", comments = "Generator version: 7.12.0-SNAPSHOT")
public class IoArgoprojEventsV1alpha1KafkaTrigger {
  public static final String SERIALIZED_NAME_COMPRESS = "compress";
  @SerializedName(SERIALIZED_NAME_COMPRESS)
  @javax.annotation.Nullable
  private Boolean compress;

  public static final String SERIALIZED_NAME_FLUSH_FREQUENCY = "flushFrequency";
  @SerializedName(SERIALIZED_NAME_FLUSH_FREQUENCY)
  @javax.annotation.Nullable
  private Integer flushFrequency;

  public static final String SERIALIZED_NAME_PARAMETERS = "parameters";
  @SerializedName(SERIALIZED_NAME_PARAMETERS)
  @javax.annotation.Nullable
  private List<IoArgoprojEventsV1alpha1TriggerParameter> parameters = new ArrayList<>();

  public static final String SERIALIZED_NAME_PARTITION = "partition";
  @SerializedName(SERIALIZED_NAME_PARTITION)
  @javax.annotation.Nullable
  private Integer partition;

  public static final String SERIALIZED_NAME_PARTITIONING_KEY = "partitioningKey";
  @SerializedName(SERIALIZED_NAME_PARTITIONING_KEY)
  @javax.annotation.Nullable
  private String partitioningKey;

  public static final String SERIALIZED_NAME_PAYLOAD = "payload";
  @SerializedName(SERIALIZED_NAME_PAYLOAD)
  @javax.annotation.Nullable
  private List<IoArgoprojEventsV1alpha1TriggerParameter> payload = new ArrayList<>();

  public static final String SERIALIZED_NAME_REQUIRED_ACKS = "requiredAcks";
  @SerializedName(SERIALIZED_NAME_REQUIRED_ACKS)
  @javax.annotation.Nullable
  private Integer requiredAcks;

  public static final String SERIALIZED_NAME_SASL = "sasl";
  @SerializedName(SERIALIZED_NAME_SASL)
  @javax.annotation.Nullable
  private IoArgoprojEventsV1alpha1SASLConfig sasl;

  public static final String SERIALIZED_NAME_SCHEMA_REGISTRY = "schemaRegistry";
  @SerializedName(SERIALIZED_NAME_SCHEMA_REGISTRY)
  @javax.annotation.Nullable
  private IoArgoprojEventsV1alpha1SchemaRegistryConfig schemaRegistry;

  public static final String SERIALIZED_NAME_TLS = "tls";
  @SerializedName(SERIALIZED_NAME_TLS)
  @javax.annotation.Nullable
  private IoArgoprojEventsV1alpha1TLSConfig tls;

  public static final String SERIALIZED_NAME_TOPIC = "topic";
  @SerializedName(SERIALIZED_NAME_TOPIC)
  @javax.annotation.Nullable
  private String topic;

  public static final String SERIALIZED_NAME_URL = "url";
  @SerializedName(SERIALIZED_NAME_URL)
  @javax.annotation.Nullable
  private String url;

  public static final String SERIALIZED_NAME_VERSION = "version";
  @SerializedName(SERIALIZED_NAME_VERSION)
  @javax.annotation.Nullable
  private String version;

  public IoArgoprojEventsV1alpha1KafkaTrigger() {
  }

  public IoArgoprojEventsV1alpha1KafkaTrigger compress(@javax.annotation.Nullable Boolean compress) {
    this.compress = compress;
    return this;
  }

  /**
   * Get compress
   * @return compress
   */
  @javax.annotation.Nullable
  public Boolean getCompress() {
    return compress;
  }

  public void setCompress(@javax.annotation.Nullable Boolean compress) {
    this.compress = compress;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger flushFrequency(@javax.annotation.Nullable Integer flushFrequency) {
    this.flushFrequency = flushFrequency;
    return this;
  }

  /**
   * Get flushFrequency
   * @return flushFrequency
   */
  @javax.annotation.Nullable
  public Integer getFlushFrequency() {
    return flushFrequency;
  }

  public void setFlushFrequency(@javax.annotation.Nullable Integer flushFrequency) {
    this.flushFrequency = flushFrequency;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger parameters(@javax.annotation.Nullable List<IoArgoprojEventsV1alpha1TriggerParameter> parameters) {
    this.parameters = parameters;
    return this;
  }

  public IoArgoprojEventsV1alpha1KafkaTrigger addParametersItem(IoArgoprojEventsV1alpha1TriggerParameter parametersItem) {
    if (this.parameters == null) {
      this.parameters = new ArrayList<>();
    }
    this.parameters.add(parametersItem);
    return this;
  }

  /**
   * Parameters is the list of parameters that is applied to resolved Kafka trigger object.
   * @return parameters
   */
  @javax.annotation.Nullable
  public List<IoArgoprojEventsV1alpha1TriggerParameter> getParameters() {
    return parameters;
  }

  public void setParameters(@javax.annotation.Nullable List<IoArgoprojEventsV1alpha1TriggerParameter> parameters) {
    this.parameters = parameters;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger partition(@javax.annotation.Nullable Integer partition) {
    this.partition = partition;
    return this;
  }

  /**
   * Get partition
   * @return partition
   */
  @javax.annotation.Nullable
  public Integer getPartition() {
    return partition;
  }

  public void setPartition(@javax.annotation.Nullable Integer partition) {
    this.partition = partition;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger partitioningKey(@javax.annotation.Nullable String partitioningKey) {
    this.partitioningKey = partitioningKey;
    return this;
  }

  /**
   * The partitioning key for the messages put on the Kafka topic. +optional.
   * @return partitioningKey
   */
  @javax.annotation.Nullable
  public String getPartitioningKey() {
    return partitioningKey;
  }

  public void setPartitioningKey(@javax.annotation.Nullable String partitioningKey) {
    this.partitioningKey = partitioningKey;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger payload(@javax.annotation.Nullable List<IoArgoprojEventsV1alpha1TriggerParameter> payload) {
    this.payload = payload;
    return this;
  }

  public IoArgoprojEventsV1alpha1KafkaTrigger addPayloadItem(IoArgoprojEventsV1alpha1TriggerParameter payloadItem) {
    if (this.payload == null) {
      this.payload = new ArrayList<>();
    }
    this.payload.add(payloadItem);
    return this;
  }

  /**
   * Payload is the list of key-value extracted from an event payload to construct the request payload.
   * @return payload
   */
  @javax.annotation.Nullable
  public List<IoArgoprojEventsV1alpha1TriggerParameter> getPayload() {
    return payload;
  }

  public void setPayload(@javax.annotation.Nullable List<IoArgoprojEventsV1alpha1TriggerParameter> payload) {
    this.payload = payload;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger requiredAcks(@javax.annotation.Nullable Integer requiredAcks) {
    this.requiredAcks = requiredAcks;
    return this;
  }

  /**
   * RequiredAcks used in producer to tell the broker how many replica acknowledgements Defaults to 1 (Only wait for the leader to ack). +optional.
   * @return requiredAcks
   */
  @javax.annotation.Nullable
  public Integer getRequiredAcks() {
    return requiredAcks;
  }

  public void setRequiredAcks(@javax.annotation.Nullable Integer requiredAcks) {
    this.requiredAcks = requiredAcks;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger sasl(@javax.annotation.Nullable IoArgoprojEventsV1alpha1SASLConfig sasl) {
    this.sasl = sasl;
    return this;
  }

  /**
   * Get sasl
   * @return sasl
   */
  @javax.annotation.Nullable
  public IoArgoprojEventsV1alpha1SASLConfig getSasl() {
    return sasl;
  }

  public void setSasl(@javax.annotation.Nullable IoArgoprojEventsV1alpha1SASLConfig sasl) {
    this.sasl = sasl;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger schemaRegistry(@javax.annotation.Nullable IoArgoprojEventsV1alpha1SchemaRegistryConfig schemaRegistry) {
    this.schemaRegistry = schemaRegistry;
    return this;
  }

  /**
   * Get schemaRegistry
   * @return schemaRegistry
   */
  @javax.annotation.Nullable
  public IoArgoprojEventsV1alpha1SchemaRegistryConfig getSchemaRegistry() {
    return schemaRegistry;
  }

  public void setSchemaRegistry(@javax.annotation.Nullable IoArgoprojEventsV1alpha1SchemaRegistryConfig schemaRegistry) {
    this.schemaRegistry = schemaRegistry;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger tls(@javax.annotation.Nullable IoArgoprojEventsV1alpha1TLSConfig tls) {
    this.tls = tls;
    return this;
  }

  /**
   * Get tls
   * @return tls
   */
  @javax.annotation.Nullable
  public IoArgoprojEventsV1alpha1TLSConfig getTls() {
    return tls;
  }

  public void setTls(@javax.annotation.Nullable IoArgoprojEventsV1alpha1TLSConfig tls) {
    this.tls = tls;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger topic(@javax.annotation.Nullable String topic) {
    this.topic = topic;
    return this;
  }

  /**
   * Get topic
   * @return topic
   */
  @javax.annotation.Nullable
  public String getTopic() {
    return topic;
  }

  public void setTopic(@javax.annotation.Nullable String topic) {
    this.topic = topic;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger url(@javax.annotation.Nullable String url) {
    this.url = url;
    return this;
  }

  /**
   * URL of the Kafka broker, multiple URLs separated by comma.
   * @return url
   */
  @javax.annotation.Nullable
  public String getUrl() {
    return url;
  }

  public void setUrl(@javax.annotation.Nullable String url) {
    this.url = url;
  }


  public IoArgoprojEventsV1alpha1KafkaTrigger version(@javax.annotation.Nullable String version) {
    this.version = version;
    return this;
  }

  /**
   * Get version
   * @return version
   */
  @javax.annotation.Nullable
  public String getVersion() {
    return version;
  }

  public void setVersion(@javax.annotation.Nullable String version) {
    this.version = version;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    IoArgoprojEventsV1alpha1KafkaTrigger ioArgoprojEventsV1alpha1KafkaTrigger = (IoArgoprojEventsV1alpha1KafkaTrigger) o;
    return Objects.equals(this.compress, ioArgoprojEventsV1alpha1KafkaTrigger.compress) &&
        Objects.equals(this.flushFrequency, ioArgoprojEventsV1alpha1KafkaTrigger.flushFrequency) &&
        Objects.equals(this.parameters, ioArgoprojEventsV1alpha1KafkaTrigger.parameters) &&
        Objects.equals(this.partition, ioArgoprojEventsV1alpha1KafkaTrigger.partition) &&
        Objects.equals(this.partitioningKey, ioArgoprojEventsV1alpha1KafkaTrigger.partitioningKey) &&
        Objects.equals(this.payload, ioArgoprojEventsV1alpha1KafkaTrigger.payload) &&
        Objects.equals(this.requiredAcks, ioArgoprojEventsV1alpha1KafkaTrigger.requiredAcks) &&
        Objects.equals(this.sasl, ioArgoprojEventsV1alpha1KafkaTrigger.sasl) &&
        Objects.equals(this.schemaRegistry, ioArgoprojEventsV1alpha1KafkaTrigger.schemaRegistry) &&
        Objects.equals(this.tls, ioArgoprojEventsV1alpha1KafkaTrigger.tls) &&
        Objects.equals(this.topic, ioArgoprojEventsV1alpha1KafkaTrigger.topic) &&
        Objects.equals(this.url, ioArgoprojEventsV1alpha1KafkaTrigger.url) &&
        Objects.equals(this.version, ioArgoprojEventsV1alpha1KafkaTrigger.version);
  }

  @Override
  public int hashCode() {
    return Objects.hash(compress, flushFrequency, parameters, partition, partitioningKey, payload, requiredAcks, sasl, schemaRegistry, tls, topic, url, version);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class IoArgoprojEventsV1alpha1KafkaTrigger {\n");
    sb.append("    compress: ").append(toIndentedString(compress)).append("\n");
    sb.append("    flushFrequency: ").append(toIndentedString(flushFrequency)).append("\n");
    sb.append("    parameters: ").append(toIndentedString(parameters)).append("\n");
    sb.append("    partition: ").append(toIndentedString(partition)).append("\n");
    sb.append("    partitioningKey: ").append(toIndentedString(partitioningKey)).append("\n");
    sb.append("    payload: ").append(toIndentedString(payload)).append("\n");
    sb.append("    requiredAcks: ").append(toIndentedString(requiredAcks)).append("\n");
    sb.append("    sasl: ").append(toIndentedString(sasl)).append("\n");
    sb.append("    schemaRegistry: ").append(toIndentedString(schemaRegistry)).append("\n");
    sb.append("    tls: ").append(toIndentedString(tls)).append("\n");
    sb.append("    topic: ").append(toIndentedString(topic)).append("\n");
    sb.append("    url: ").append(toIndentedString(url)).append("\n");
    sb.append("    version: ").append(toIndentedString(version)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("compress");
    openapiFields.add("flushFrequency");
    openapiFields.add("parameters");
    openapiFields.add("partition");
    openapiFields.add("partitioningKey");
    openapiFields.add("payload");
    openapiFields.add("requiredAcks");
    openapiFields.add("sasl");
    openapiFields.add("schemaRegistry");
    openapiFields.add("tls");
    openapiFields.add("topic");
    openapiFields.add("url");
    openapiFields.add("version");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to IoArgoprojEventsV1alpha1KafkaTrigger
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!IoArgoprojEventsV1alpha1KafkaTrigger.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in IoArgoprojEventsV1alpha1KafkaTrigger is not found in the empty JSON string", IoArgoprojEventsV1alpha1KafkaTrigger.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!IoArgoprojEventsV1alpha1KafkaTrigger.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `IoArgoprojEventsV1alpha1KafkaTrigger` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      if (jsonObj.get("parameters") != null && !jsonObj.get("parameters").isJsonNull()) {
        JsonArray jsonArrayparameters = jsonObj.getAsJsonArray("parameters");
        if (jsonArrayparameters != null) {
          // ensure the json data is an array
          if (!jsonObj.get("parameters").isJsonArray()) {
            throw new IllegalArgumentException(String.format("Expected the field `parameters` to be an array in the JSON string but got `%s`", jsonObj.get("parameters").toString()));
          }

          // validate the optional field `parameters` (array)
          for (int i = 0; i < jsonArrayparameters.size(); i++) {
            IoArgoprojEventsV1alpha1TriggerParameter.validateJsonElement(jsonArrayparameters.get(i));
          };
        }
      }
      if ((jsonObj.get("partitioningKey") != null && !jsonObj.get("partitioningKey").isJsonNull()) && !jsonObj.get("partitioningKey").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `partitioningKey` to be a primitive type in the JSON string but got `%s`", jsonObj.get("partitioningKey").toString()));
      }
      if (jsonObj.get("payload") != null && !jsonObj.get("payload").isJsonNull()) {
        JsonArray jsonArraypayload = jsonObj.getAsJsonArray("payload");
        if (jsonArraypayload != null) {
          // ensure the json data is an array
          if (!jsonObj.get("payload").isJsonArray()) {
            throw new IllegalArgumentException(String.format("Expected the field `payload` to be an array in the JSON string but got `%s`", jsonObj.get("payload").toString()));
          }

          // validate the optional field `payload` (array)
          for (int i = 0; i < jsonArraypayload.size(); i++) {
            IoArgoprojEventsV1alpha1TriggerParameter.validateJsonElement(jsonArraypayload.get(i));
          };
        }
      }
      // validate the optional field `sasl`
      if (jsonObj.get("sasl") != null && !jsonObj.get("sasl").isJsonNull()) {
        IoArgoprojEventsV1alpha1SASLConfig.validateJsonElement(jsonObj.get("sasl"));
      }
      // validate the optional field `schemaRegistry`
      if (jsonObj.get("schemaRegistry") != null && !jsonObj.get("schemaRegistry").isJsonNull()) {
        IoArgoprojEventsV1alpha1SchemaRegistryConfig.validateJsonElement(jsonObj.get("schemaRegistry"));
      }
      // validate the optional field `tls`
      if (jsonObj.get("tls") != null && !jsonObj.get("tls").isJsonNull()) {
        IoArgoprojEventsV1alpha1TLSConfig.validateJsonElement(jsonObj.get("tls"));
      }
      if ((jsonObj.get("topic") != null && !jsonObj.get("topic").isJsonNull()) && !jsonObj.get("topic").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `topic` to be a primitive type in the JSON string but got `%s`", jsonObj.get("topic").toString()));
      }
      if ((jsonObj.get("url") != null && !jsonObj.get("url").isJsonNull()) && !jsonObj.get("url").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `url` to be a primitive type in the JSON string but got `%s`", jsonObj.get("url").toString()));
      }
      if ((jsonObj.get("version") != null && !jsonObj.get("version").isJsonNull()) && !jsonObj.get("version").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `version` to be a primitive type in the JSON string but got `%s`", jsonObj.get("version").toString()));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!IoArgoprojEventsV1alpha1KafkaTrigger.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'IoArgoprojEventsV1alpha1KafkaTrigger' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<IoArgoprojEventsV1alpha1KafkaTrigger> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(IoArgoprojEventsV1alpha1KafkaTrigger.class));

       return (TypeAdapter<T>) new TypeAdapter<IoArgoprojEventsV1alpha1KafkaTrigger>() {
           @Override
           public void write(JsonWriter out, IoArgoprojEventsV1alpha1KafkaTrigger value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public IoArgoprojEventsV1alpha1KafkaTrigger read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of IoArgoprojEventsV1alpha1KafkaTrigger given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of IoArgoprojEventsV1alpha1KafkaTrigger
   * @throws IOException if the JSON string is invalid with respect to IoArgoprojEventsV1alpha1KafkaTrigger
   */
  public static IoArgoprojEventsV1alpha1KafkaTrigger fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, IoArgoprojEventsV1alpha1KafkaTrigger.class);
  }

  /**
   * Convert an instance of IoArgoprojEventsV1alpha1KafkaTrigger to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

